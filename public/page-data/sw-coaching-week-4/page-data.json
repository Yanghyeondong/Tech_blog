{"componentChunkName":"component---src-templates-post-template-tsx","path":"/sw-coaching-week-4/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<p><em>본 포스트는 IOWA 대학 <strong>이강표</strong>(Kang-Pyo Lee) 박사님의 허락을 구하고 강의를 정리한 것입니다.</em><br>\n<em>강의 사진, 코드의 저작권은 모두 이강표 박사님께 있습니다.</em></p>\n<h2 id=\"1-강의-정리\" style=\"position:relative;\"><a href=\"#1-%EA%B0%95%EC%9D%98-%EC%A0%95%EB%A6%AC\" aria-label=\"1 강의 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. 강의 정리</h2>\n<p><del>설 연휴로 포스팅이 좀 밀렸습니다 😏</del><br>\n<br>\n<strong>Text analytics</strong> 핵심<br>\n= 텍스트에서 정보를 추출하는 것 (deriving information from text)<br>\n<br>\n<br>\n<strong>Types of Data</strong><br>\n= Text data는 Unstructured data에 해당한다\n<img src=\"/f213c6d0ed83aaa9f3d2f687c51e2dca/2.png\" alt=\"2\"><br>\n<br>\n<br>\n<strong>Text analytics</strong> 단계<br>\n<br>\n<img src=\"/d7b50d2ad4e34a283ca59586da0ea1f1/3.png\" alt=\"3\"><br>\n<br>\n<br>\n<strong>Part-of-Speech (PoS) Tagging</strong><br>\n= 단어를 문법적 특징으로 분리하여 Tagging.<br>\nTag 잘 정리된 사이트. <a href=\"https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html\" target=\"_blank\" rel=\"nofollow\">https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html</a><br>\n<br>\n<br>\n<strong>ngrams</strong> 활용<br>\n= 의미 있는 새로운 결과물도 만들어 내지만, 필요 없는 노이즈도 많이 생기게 된다.<br>\n해당 부분을 잘 고려하자.<br>\n<br>\n<br>\n<strong>Counter()</strong> 활용<br>\n= 파이썬에 내장되어 있는 <code class=\"language-text\">Counter()</code>를 사용한다. 이때, 각 Text 마다 단어가 여러 번 나온다면 그대로 count 할지, 1번으로 통합해서 count 할지 잘 정하도록 하자.<br>\n<br>\n<br>\n<strong>Sentiment Analysis</strong> 활용<br>\n= 많이 사용되기는 하지만, 현재 기준으로 생각보다 정확도가 높지는 않다.<br>\n<img src=\"/84d4d4d982bcb29455cd2464fc9961d5/5.png\" alt=\"5\"></p>\n<h3 id=\"tip\" style=\"position:relative;\"><a href=\"#tip\" aria-label=\"tip permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>⭐TIP!⭐</h3>\n<p><strong>Text analytics</strong>는 <strong>자연어</strong>에 대한 분석이므로 100%의 정확도를 보여주지 <strong>않는다!</strong><br>\n=오차나 노이즈가 항상 존재한다<br>\nex.) Part-of-Speech (PoS) Tagging, Sentiment Analysis</p>\n<p><img src=\"/9c2036c082bcbc8619482d2feb79b3a3/4.png\" alt=\"4\"></p>\n<h2 id=\"2-코드-코칭\" style=\"position:relative;\"><a href=\"#2-%EC%BD%94%EB%93%9C-%EC%BD%94%EC%B9%AD\" aria-label=\"2 코드 코칭 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 코드 코칭</h2>\n<p><em>코드 전문은 분량상 제외하였으며, 피드백 위주로 정리하였습니다. Colab 환경을 기반으로 합니다.</em></p>\n<h3 id=\"리스트-컴프리헨션-startswith-활용\" style=\"position:relative;\"><a href=\"#%EB%A6%AC%EC%8A%A4%ED%8A%B8-%EC%BB%B4%ED%94%84%EB%A6%AC%ED%97%A8%EC%85%98-startswith-%ED%99%9C%EC%9A%A9\" aria-label=\"리스트 컴프리헨션 startswith 활용 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>리스트 컴프리헨션, startswith() 활용</h3>\n<p><code class=\"language-text\">nltk</code>의 <code class=\"language-text\">pos_tag</code>를 사용하면 각 word와 그에 해당하는 tag를 묶은 튜플을 얻게 됩니다. 여기서 <code class=\"language-text\">nouns</code>만 뽑아내고 싶은 경우, <code class=\"language-text\">startswith()</code>와 <strong>리스트 컴프리헨션</strong>으로 간단하게 구현가능합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">df<span class=\"token punctuation\">[</span><span class=\"token string\">\"tagged_words\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>words<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> nltk<span class=\"token punctuation\">.</span>pos_tag<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"nouns\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>tagged_words<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>word <span class=\"token keyword\">for</span> word<span class=\"token punctuation\">,</span> tag <span class=\"token keyword\">in</span> x <span class=\"token keyword\">if</span> tag<span class=\"token punctuation\">.</span>startswith<span class=\"token punctuation\">(</span><span class=\"token string\">\"NN\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><code class=\"language-text\">startswith()</code>를 사용한 이유는 다음의 tag를 모두 담기 위함입니다.</p>\n<blockquote>\n<p>NN\t= Noun, singular or mass<br>\nNNS\t= Noun, plural<br>\nNNP\t= Proper noun, singular<br>\nNNPS\t= Proper noun, plural</p>\n</blockquote>\n<h3 id=\"함수-최적화\" style=\"position:relative;\"><a href=\"#%ED%95%A8%EC%88%98-%EC%B5%9C%EC%A0%81%ED%99%94\" aria-label=\"함수 최적화 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>함수 최적화</h3>\n<p>저번 글과 비슷하게, 시간이 오래 걸리는 함수들은 불필요하게 낭비되는 곳이 없는지 확인합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token comment\"># Bad</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"polarity\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> TextBlob<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>sentiment<span class=\"token punctuation\">.</span>polarity<span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"subjectivity\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> TextBlob<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>sentiment<span class=\"token punctuation\">.</span>subjectivity<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\"><span class=\"token comment\"># Good</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"sentiment\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>text<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> TextBlob<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>sentiment<span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"polarity\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>sentiment<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">.</span>polarity<span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">\"subjectivity\"</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>sentiment<span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> x<span class=\"token punctuation\">.</span>subjectivity<span class=\"token punctuation\">)</span></code></pre></div>\n<h3 id=\"stopwords\" style=\"position:relative;\"><a href=\"#stopwords\" aria-label=\"stopwords permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stopwords</h3>\n<p>stopwords를 만들 때는 아래와 같이 <code class=\"language-text\">global</code>, <code class=\"language-text\">local</code>를 구분하여 만들어 주는 것이 좋습니다. <code class=\"language-text\">global_stopwords</code>의 경우 <code class=\"language-text\">nltk.corpus.stopwords</code>를 활용하며, <code class=\"language-text\">local_stopwords</code>은 <code class=\"language-text\">string.punctuation</code>을 활용합니다.<br>\n<br>\n특히 본인이 직접 결과를 보면서 필요 없다고 판단되는 것들을 직접 <code class=\"language-text\">local</code>에 추가시켜주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"py\"><pre class=\"language-py\"><code class=\"language-py\">global_stopwords <span class=\"token operator\">=</span> nltk<span class=\"token punctuation\">.</span>corpus<span class=\"token punctuation\">.</span>stopwords<span class=\"token punctuation\">.</span>words<span class=\"token punctuation\">(</span><span class=\"token string\">\"english\"</span><span class=\"token punctuation\">)</span> \nlocal_stopwords <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>c <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> string<span class=\"token punctuation\">.</span>punctuation<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span>\\\n                  <span class=\"token punctuation\">[</span><span class=\"token string\">'‘'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'’'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'—'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'…'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span>\\\n                  <span class=\"token punctuation\">[</span><span class=\"token string\">'https'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"'s\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"n't\"</span><span class=\"token punctuation\">]</span> <span class=\"token comment\"># My own stopwords in this model</span></code></pre></div>\n<h2 id=\"3-느낀-점\" style=\"position:relative;\"><a href=\"#3-%EB%8A%90%EB%82%80-%EC%A0%90\" aria-label=\"3 느낀 점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 느낀 점</h2>\n<p><code class=\"language-text\">nltk</code>의 여러 새로운 기능들과 <code class=\"language-text\">TextBlob()</code>의 <strong>polarity, subjectivity</strong> 분석이 상당히 재미있었습니다. 실제로 현업에서도 인기 있는 분석들을 직접 활용 해보니 신기하면서도 왠지 모를 성취감도 생겼습니다. 개인적으로 모으고 있는 <strong>CNET</strong> 사이트 데이터에도 이를 빨리 적용시켜 보고 싶습니다 😋.</p>\n<h2 id=\"source\" style=\"position:relative;\"><a href=\"#source\" aria-label=\"source permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Source</h2>\n<ul>\n<li>성균관대학교 SW Coaching 프로그램</li>\n<li>이강표(Kang-Pyo Lee) 박사님 강의</li>\n</ul>\n<!--\n1주 Web Scraping 기초\n2주 Web Scraping 심화\n3주 Pandas Dataframe 다루기\n4주 텍스트 데이터 처리\n5주 문서 클러스터링 및 토픽 모델링\n6주 개인 프로젝트 발표\n-->","id":"f5d03c1b-8f67-5a8d-bb07-22e28cd3a26b","tableOfContents":"<ul>\n<li>\n<p><a href=\"#1-%EA%B0%95%EC%9D%98-%EC%A0%95%EB%A6%AC\">1. 강의 정리</a></p>\n<ul>\n<li><a href=\"#tip\">⭐TIP!⭐</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-%EC%BD%94%EB%93%9C-%EC%BD%94%EC%B9%AD\">2. 코드 코칭</a></p>\n<ul>\n<li><a href=\"#%EB%A6%AC%EC%8A%A4%ED%8A%B8-%EC%BB%B4%ED%94%84%EB%A6%AC%ED%97%A8%EC%85%98-startswith-%ED%99%9C%EC%9A%A9\">리스트 컴프리헨션, startswith() 활용</a></li>\n<li><a href=\"#%ED%95%A8%EC%88%98-%EC%B5%9C%EC%A0%81%ED%99%94\">함수 최적화</a></li>\n<li><a href=\"#stopwords\">Stopwords</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#3-%EB%8A%90%EB%82%80-%EC%A0%90\">3. 느낀 점</a></p>\n</li>\n<li>\n<p><a href=\"#source\">Source</a></p>\n</li>\n</ul>","frontmatter":{"title":"[SW Coaching - Week 4] 텍스트 데이터 처리","summary":"파이썬 Web Scraping, PoS Tagging, ngrams, TextBlob","date":"2023.02.04.","categories":["Python","Web Scraping","SW Coaching"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABGUlEQVQoz41RW4qDQBDMbWLiExUR/5IovgOCKGhEDd7A+1OhG2aZNSa7H0XbZU9N1fRB13UYhvELpml+7T9xpHUQglQVRcHxeORKOJ1ODMGLnkC94GQNFiTYto00TVEUBcIwxO12Y1wuF8RxzPz1ekUURfw/z3MkScKccMuC4sNxHPR9j2EYuHZdh6qq0DQNxnHE4/HAsiyo6xplWWKaJp5r25YFhbGvkc/nMzRN++Go30Ym/i2y/NAClmVBVVXM84x1XfF8Ptkdzctz8nLeHArIPT1FEATwPI8v2c583LJMyr2ISZUc7136L0Gq5CjLMpT3O2+Ztm5uLt2e/9MhRfV9n6vrujCM98i7S5HfUI5CMWnTAnvuZMEXB+levv+hLG8AAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/3c83c/title.png","srcSet":"/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/899ed/title.png 318w,\n/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/68d52/title.png 636w,\n/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/3c83c/title.png 1271w","sizes":"(min-width: 1271px) 1271px, 100vw"},"sources":[{"srcSet":"/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/5e5b9/title.webp 318w,\n/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/273d4/title.webp 636w,\n/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/79620/title.webp 1271w","type":"image/webp","sizes":"(min-width: 1271px) 1271px, 100vw"}]},"width":1271,"height":713}},"publicURL":"/static/0e4a5cf1cee7f03e87f3654a34a8b0e5/title.png"}}}}]}},"pageContext":{"slug":"/sw-coaching-week-4/"}},"staticQueryHashes":[]}